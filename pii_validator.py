#!/usr/bin/env python3
"""
Ground Truth PII Validator
Tests model against human-curated dataset with definitive correct answers
"""

import pandas as pd
import requests
import json
from typing import Dict
import time
import sys
import os
from datetime import datetime

class GroundTruthValidator:
    def __init__(self, model_url="http://localhost:11434", model_name="llama3.1:8b"):
        self.model_url = model_url
        self.model_name = model_name
        self.api_endpoint = f"{model_url}/api/generate"
        
    def create_validation_prompt(self, table_name: str, column_name: str, 
                               column_datatype: str, column_length: int, 
                               guessed_classification: str) -> str:
        """Create validation prompt"""
        
        prompt = f"""You are validating a PII classification guess. Your job is to check if the GUESS is correct.

## Available PII Types
- Address, Address 2, Age, Bank account, City, Country, Date of birth
- Drivers license number, Email address, First name, Full name
- Insurance number, Last name, Medical records, Medicare ID
- National Identifier, Phone, Postal Code, NOT_PII

## TASK: Check if the guess is correct
Column: {column_name} (in {table_name} table)
Data Type: {column_datatype}, Length: {column_length}
GUESS: "{guessed_classification}"

## Step-by-step validation:
1. What SHOULD this column be classified as?
2. What was GUESSED: "{guessed_classification}"
3. Do they MATCH?

## Classification Rules
- Human names (manager_name, contact_person, employee_name, doctor_name, customer_rep) = "Full name"
- Email fields (user_email, contact_email, email_address) = "Email address"  
- Phone fields (phone_number, contact_phone, work_phone) = "Phone"
- System IDs (user_id, session_id, order_id, patient_id) = "NOT_PII"
- Business data (salary_amount, department_code, company_name) = "NOT_PII"
- Vague fields (contact_info, user_info, personal_data) are ambiguous

## Response Format (JSON only)
{{
  "should_be": "what_the_correct_classification_should_be",
  "was_guessed": "{guessed_classification}",
  "is_correct": true/false,
  "confidence": "HIGH/MEDIUM/LOW", 
  "correct_classification": "only_if_guess_was_wrong",
  "reasoning": "Step 1: Should be X. Step 2: Guessed Y. Step 3: Match = true/false"
}}

Example:
- Column: user_id, Guessed: "NOT_PII"
- Response: {{"should_be": "NOT_PII", "was_guessed": "NOT_PII", "is_correct": true, ...}}

- Column: manager_name, Guessed: "NOT_PII"  
- Response: {{"should_be": "Full name", "was_guessed": "NOT_PII", "is_correct": false, ...}}

Response:"""
        
        return prompt
    
    def query_model(self, prompt: str) -> Dict:
        """Query the model and return parsed response"""
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.0,
                "max_tokens": 300
            }
        }
        
        try:
            response = requests.post(self.api_endpoint, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            response_text = result.get('response', '').strip()
            
            # Extract JSON
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                return {"is_correct": None, "confidence": "LOW", "correct_classification": "UNKNOWN", "reasoning": "No JSON found", "should_be": "Unknown", "was_guessed": "Unknown"}
                
        except Exception as e:
            return {"is_correct": None, "confidence": "LOW", "correct_classification": "ERROR", "reasoning": f"Error: {str(e)}", "should_be": "Error", "was_guessed": "Error"}
    
    def convert_to_simple_result(self, model_response: Dict, human_eval: str) -> str:
        """Convert model response to match human evaluation categories"""
        
        is_correct = model_response.get('is_correct')
        confidence = model_response.get('confidence', 'LOW')
        
        if human_eval == "CORRECT":
            # Should return True Positive
            return "True Positive" if (is_correct is True and confidence in ['HIGH', 'MEDIUM']) else "False"
            
        elif human_eval == "INCORRECT":  
            # Should return Negative
            return "Negative" if (is_correct is False and confidence in ['HIGH', 'MEDIUM']) else "False"
            
        elif human_eval == "AMBIGUOUS":
            # Should return Unsure (low confidence or uncertainty)
            return "Unsure" if (confidence == 'LOW' or is_correct is None) else "False"
        
        return "Unknown"
    
    def test_against_ground_truth(self, dataset_file: str) -> pd.DataFrame:
        """Test model against ground truth dataset"""
        
        print("ðŸ“Š Loading ground truth dataset...")
        df = pd.read_csv(dataset_file)
        
        print(f"ðŸ§ª Testing {len(df)} cases against ground truth...")
        print()
        
        results = []
        correct_predictions = 0
        
        for idx, row in df.iterrows():
            table_col = f"{row['Table Name']}.{row['Column Name']}"
            human_eval = row['Human Evaluation']
            correct_classification = row['Correct Classification']
            
            print(f"[{idx + 1}/{len(df)}] {table_col}")
            print(f"    Guessed: {row['Guessed Classification']}")
            print(f"    Human says: {human_eval}")
            if human_eval == "INCORRECT":
                print(f"    Should be: {correct_classification}")
            
            # Get model prediction
            prompt = self.create_validation_prompt(
                table_name=row['Table Name'],
                column_name=row['Column Name'],
                column_datatype=row['Column Datatype'],
                column_length=row['Column Length'],
                guessed_classification=row['Guessed Classification']
            )
            
            model_response = self.query_model(prompt)
            model_result = self.convert_to_simple_result(model_response, human_eval)
            
            # Check if model agrees with human
            is_match = (
                (human_eval == "CORRECT" and model_result == "True Positive") or
                (human_eval == "INCORRECT" and model_result == "Negative") or  
                (human_eval == "AMBIGUOUS" and model_result == "Unsure")
            )
            
            print(f"    Should be: {model_response.get('should_be', 'Unknown')}")
            print(f"    Was guessed: {model_response.get('was_guessed', 'Unknown')}")
            print(f"    Match: {model_response.get('is_correct', 'Unknown')}")
            
            if is_match:
                correct_predictions += 1
                print(f"    Model: {model_result} âœ…")
            else:
                print(f"    Model: {model_result} âŒ")
                print(f"    Expected: {human_eval}")
            
            print(f"    Reasoning: {model_response.get('reasoning', 'No reasoning')}")
            print()
            
            # Store results
            results.append({
                'table_column': table_col,
                'guessed_classification': row['Guessed Classification'],
                'human_evaluation': human_eval,
                'correct_classification': correct_classification,
                'model_result': model_result,
                'is_match': is_match,
                'model_confidence': model_response.get('confidence', 'UNKNOWN'),
                'model_should_be': model_response.get('should_be', ''),
                'model_was_guessed': model_response.get('was_guessed', ''),
                'model_is_correct': model_response.get('is_correct'),
                'model_suggestion': model_response.get('correct_classification', ''),
                'model_reasoning': model_response.get('reasoning', ''),
                'notes': row.get('Notes', '')
            })
            
            time.sleep(0.3)
        
        # Calculate performance
        accuracy = correct_predictions / len(df) * 100
        
        print("="*80)
        print("ðŸŽ¯ GROUND TRUTH VALIDATION RESULTS")
        print("="*80)
        print(f"ðŸ“Š Overall Accuracy: {correct_predictions}/{len(df)} ({accuracy:.1f}%)")
        
        # Break down by category
        results_df = pd.DataFrame(results)
        
        for eval_type in ['CORRECT', 'INCORRECT', 'AMBIGUOUS']:
            subset = results_df[results_df['human_evaluation'] == eval_type]
            if len(subset) > 0:
                matches = subset[subset['is_match'] == True]
                subset_accuracy = len(matches) / len(subset) * 100
                print(f"   {eval_type}: {len(matches)}/{len(subset)} ({subset_accuracy:.1f}%)")
        
        # Show mismatches
        mismatches = results_df[results_df['is_match'] == False]
        if len(mismatches) > 0:
            print(f"\nâŒ MISMATCHES ({len(mismatches)} cases):")
            print("-"*60)
            for _, row in mismatches.iterrows():
                print(f"â€¢ {row['table_column']}")
                print(f"  Human: {row['human_evaluation']} | Model: {row['model_result']}")
                print(f"  Issue: {row['notes']}")
                print()
        
        return results_df
    
    def test_connection(self) -> bool:
        """Test model connection"""
        try:
            test_payload = {
                "model": self.model_name,
                "prompt": "Say 'OK'",
                "stream": False
            }
            response = requests.post(self.api_endpoint, json=test_payload, timeout=10)
            response.raise_for_status()
            print(f"âœ… Connected to {self.model_name}")
            return True
        except Exception as e:
            print(f"âŒ Connection failed: {e}")
            return False

def create_ground_truth_dataset():
    """Create the ground truth dataset file"""
    # Dataset content from the artifact above
    dataset_content = """Table Name,Column Name,Column Datatype,Column Length,Guessed Classification,Human Evaluation,Correct Classification,Notes
users,user_id,integer,11,NOT_PII,CORRECT,NOT_PII,System identifier - clearly not PII
users,email_address,varchar,255,Email address,CORRECT,Email address,Perfect match - email field
users,first_name,varchar,50,First name,CORRECT,First name,Perfect match
users,phone_number,varchar,15,Phone,CORRECT,Phone,Perfect match
users,date_of_birth,date,10,Date of birth,CORRECT,Date of birth,Perfect match
users,manager_name,varchar,100,NOT_PII,INCORRECT,Full name,Manager name is a person's name - always PII
users,contact_person,varchar,80,First name,INCORRECT,Full name,Contact person is typically full name not just first
users,user_email,varchar,255,Phone,INCORRECT,Email address,Obviously wrong - email field classified as phone
users,contact_info,varchar,150,Email address,AMBIGUOUS,Email address OR Phone,Could be email OR phone - too vague to be certain
users,personal_data,text,500,First name,AMBIGUOUS,Full name OR Medical records OR Multiple,Too vague - could be various PII types
employees,employee_id,integer,11,NOT_PII,CORRECT,NOT_PII,System identifier
employees,ssn,varchar,11,National Identifier,CORRECT,National Identifier,SSN is correctly a national identifier
employees,social_security_number,varchar,11,National Identifier,CORRECT,National Identifier,Full SSN field name
employees,employee_name,varchar,100,First name,INCORRECT,Full name,Employee name is typically full name
employees,work_phone,varchar,15,Phone,CORRECT,Phone,Work phone is still phone PII
employees,salary_amount,decimal,10,NOT_PII,CORRECT,NOT_PII,Salary is business data
employees,department_code,varchar,5,NOT_PII,CORRECT,NOT_PII,Department code is business data
employees,emergency_contact,varchar,100,Phone,INCORRECT,Full name,Emergency contact is a person's name not phone number
employees,license_number,varchar,20,Drivers license number,CORRECT,Drivers license number,Perfect match
customers,customer_number,varchar,20,NOT_PII,CORRECT,NOT_PII,Business identifier not personal
customers,company_name,varchar,200,NOT_PII,CORRECT,NOT_PII,Business data
customers,billing_address,varchar,200,Address,CORRECT,Address,Perfect match
customers,customer_phone,varchar,15,Email address,INCORRECT,Phone,Phone field classified as email
customers,contact_email,varchar,255,Email address,CORRECT,Email address,Perfect match
customers,zip_code,varchar,10,Postal Code,CORRECT,Postal Code,Perfect match
customers,customer_rep,varchar,100,NOT_PII,INCORRECT,Full name,Customer rep is a person's name
customers,account_holder,varchar,100,Bank account,INCORRECT,Full name,Account holder is a person's name not account number
customers,credit_card_num,varchar,19,Bank account,INCORRECT,Bank account,Credit card should be bank account (financial instrument)
orders,order_id,integer,11,NOT_PII,CORRECT,NOT_PII,System identifier
orders,tracking_number,varchar,30,NOT_PII,CORRECT,NOT_PII,Business identifier
orders,customer_contact,varchar,100,Phone,AMBIGUOUS,Phone OR Full name,Could be phone number or contact person name
orders,delivery_notes,text,500,NOT_PII,CORRECT,NOT_PII,Delivery instructions are business data
orders,recipient_name,varchar,100,Full name,CORRECT,Full name,Perfect match
medical,patient_id,integer,11,NOT_PII,CORRECT,NOT_PII,System identifier
medical,patient_name,varchar,100,Full name,CORRECT,Full name,Perfect match
medical,medical_record_number,varchar,20,NOT_PII,CORRECT,NOT_PII,System identifier for medical records
medical,diagnosis_notes,text,2000,Medical records,CORRECT,Medical records,Perfect match
medical,doctor_name,varchar,100,NOT_PII,INCORRECT,Full name,Doctor name is a person's name
medical,medicare_id,varchar,15,Medicare ID,CORRECT,Medicare ID,Perfect match
finance,account_number,varchar,20,Bank account,CORRECT,Bank account,Perfect match
finance,routing_number,varchar,9,Bank account,CORRECT,Bank account,Banking information
finance,cardholder_name,varchar,100,Full name,CORRECT,Full name,Perfect match
finance,card_expiry,varchar,7,NOT_PII,CORRECT,NOT_PII,Card expiry is not personally identifying
logs,session_id,varchar,64,NOT_PII,CORRECT,NOT_PII,System identifier
logs,ip_address,varchar,45,NOT_PII,CORRECT,NOT_PII,IP addresses are not direct PII
logs,user_agent,text,500,NOT_PII,CORRECT,NOT_PII,Browser info is not PII
logs,user_info,varchar,200,First name,AMBIGUOUS,First name OR Email address OR Multiple,Too generic - could be various PII types
ambiguous,contact_details,varchar,150,Email address,AMBIGUOUS,Email address OR Phone,Could be either contact method
ambiguous,personal_identifier,varchar,25,National Identifier,AMBIGUOUS,National Identifier OR Drivers license number,Could be various ID types
ambiguous,address_info,varchar,300,Address,AMBIGUOUS,Address OR City OR Postal Code,Too vague - could be full address or components"""
    
    return dataset_content

def main():
    """Main execution function"""
    print("ðŸŽ¯ Ground Truth PII Validator")
    print("="*50)
    
    # Configuration
    MODEL_URL = "http://localhost:11434"
    MODEL_NAME = "llama3.1:8b"
    DATASET_FILE = "ground_truth_pii_dataset.csv"
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    RESULTS_FILE = f"ground_truth_results_{timestamp}.csv"
    
    print(f"ðŸ¤– Model: {MODEL_NAME}")
    print(f"ðŸ“Š Dataset: {DATASET_FILE}")
    print(f"ðŸ’¾ Results: {RESULTS_FILE}")
    print()
    
    # Create dataset if needed
    if not os.path.exists(DATASET_FILE):
        print(f"ðŸ“„ Creating ground truth dataset...")
        with open(DATASET_FILE, "w") as f:
            f.write(create_ground_truth_dataset())
        print("âœ… Ground truth dataset created with 47 human-curated test cases")
        print("   ðŸ“‹ Breakdown: 26 CORRECT, 12 INCORRECT, 9 AMBIGUOUS")
        print()
    
    # Initialize validator
    validator = GroundTruthValidator(model_url=MODEL_URL, model_name=MODEL_NAME)
    
    # Test connection
    if not validator.test_connection():
        sys.exit(1)
    
    print()
    
    # Run validation
    try:
        results_df = validator.test_against_ground_truth(DATASET_FILE)
        
        # Save results
        results_df.to_csv(RESULTS_FILE, index=False)
        
        print(f"ðŸ“ Detailed results saved to: {RESULTS_FILE}")
        print()
        print("ðŸ’¡ Next steps based on accuracy:")
        print("   â€¢ >85%: Model is working well")
        print("   â€¢ 70-85%: Try prompt adjustments")  
        print("   â€¢ <70%: Consider different model (phi3:mini, mistral:7b)")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()